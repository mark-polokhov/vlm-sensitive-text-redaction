{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4362a078",
   "metadata": {},
   "source": [
    "# Использование LLaVA для автоматической генерации описаний изображений\n",
    "### Полохов Марк"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242ba76",
   "metadata": {},
   "source": [
    "Предварительная подготовка ноутбука:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fcd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14912364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"X:/Programming/Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48cb27aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas numpy matplotlib seaborn scikit-learn tqdm\n",
    "%pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "%pip install -q transformers pillow nltk evaluate accelerate kagglehub\n",
    "%pip install -q rouge_score\n",
    "%pip install -q jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950359ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\Programming\\Education\\master_2\\multimodal\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# import kagglehub\n",
    "# если нужно подгрузить датасет из каггла\n",
    "\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05af108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.6.0+cu124\n",
      "CUDA status: Available\n",
      "CUDA Device Count: 1\n",
      "GPU Device: NVIDIA GeForce RTX 4070 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"CUDA status:\", \"Available\" if torch.cuda.is_available() else \"Not Available\")\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "print(\"GPU Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f4cd3",
   "metadata": {},
   "source": [
    "<img src=\"https://i.pinimg.com/1200x/a9/ce/a1/a9cea1a2e6b751fd77ea69c310d1ae52.jpg\" width=480px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421bccc9",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5136a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53ff3c05f8f415d851f9ae34f1a0334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlavaNextForConditionalGeneration(\n",
       "  (model): LlavaNextModel(\n",
       "    (vision_tower): CLIPVisionModel(\n",
       "      (vision_model): CLIPVisionTransformer(\n",
       "        (embeddings): CLIPVisionEmbeddings(\n",
       "          (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "          (position_embedding): Embedding(577, 1024)\n",
       "        )\n",
       "        (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder): CLIPEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-23): 24 x CLIPEncoderLayer(\n",
       "              (self_attn): CLIPAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (multi_modal_projector): LlavaNextMultiModalProjector(\n",
       "      (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (act): GELUActivation()\n",
       "      (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    )\n",
       "    (language_model): MistralModel(\n",
       "      (embed_tokens): Embedding(32064, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x MistralDecoderLayer(\n",
       "          (self_attn): MistralAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MistralMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "          (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      (rotary_emb): MistralRotaryEmbedding()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"llava-hf/llava-v1.6-mistral-7b-hf\"  # Возьму версию на мистрале, надеюсь комп вытянет\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(model_id)\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc2ab8",
   "metadata": {},
   "source": [
    "<img src=\"https://i.pinimg.com/736x/4e/e7/c0/4ee7c03fc8ebadd2f24334847a90ceba.jpg\" width=480px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b0aa2",
   "metadata": {},
   "source": [
    "### Функция капшенинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b0d3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image):\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=500,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=processor.tokenizer.eos_token_id,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    caption = generated_text.split(\"[/INST] \")[-1].strip()\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cca06",
   "metadata": {},
   "source": [
    "## Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0261bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Ты детектор PII в документах (паспорта, ID, квитанции). Игнорируй lorem ipsum, placeholder текст, заголовки форм. Ищи ТОЛЬКО реальные персональные данные:\n",
    "\n",
    "ПРИОРИТЕТНЫЕ ЦЕЛИ (найди ВСЕ):\n",
    "1. Имена/фамилии рядом с \"ФИО\", \"Name\", \"Surname\"\n",
    "2. Даты рождения \"ДР\", \"DOB\", \"Дата рождения\" + ДД.ММ.ГГГГ\n",
    "3. Серии/номера документов \"Серия\", \"№\", \"Series\", \"Number\" + 6-10 цифр/букв\n",
    "4. Адреса \"Адрес\", \"Address\", улица+дом\n",
    "5. Телефоны \"+7\", \"8\", 10-11 цифр\n",
    "6. Email @gmail, @yandex и т.д.\n",
    "7. Паспортные фото/лица (bbox по лицу)\n",
    "8. QR-коды в документах\n",
    "\n",
    "Выведи ТОЛЬКО JSON:\n",
    "\n",
    "{\n",
    "  \"pii_detections\": [\n",
    "    {\n",
    "      \"bbox\": [x1,y1,x2,y2],\n",
    "      \"type\": \"full_name | passport_number | birth_date | address | phone | email | face | qr_code\",\n",
    "      \"content\": \"ТОЧНЫЙ текст из bbox\",\n",
    "      \"confidence\": \"high/medium/low\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "ПРАВИЛА:\n",
    "- НЕ включай lorem ipsum, \"sample text\", заголовки полей\n",
    "- Каждый тип данных = отдельный bbox (ФИО и серия паспорта = 2 bbox)\n",
    "- Лицо человека = bbox с type: \"face\"\n",
    "- Координаты в пикселях изображения\n",
    "- Пусто = \"pii_detections\": []\n",
    "\n",
    "ТОЛЬКО JSON!\n",
    "\"\"\"\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "          {\"type\": \"text\", \"text\": prompt},\n",
    "          {\"type\": \"image\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e75ea",
   "metadata": {},
   "source": [
    "### Генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af1ac64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"1000_F_241452512_SfahINK75By3VLfVxHmSQajt9iGK3EzM.jpg\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95940071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"pii_detections\": [\\n    {\\n      \"bbox\": [0.239,0.537,0.494,0.829],\\n      \"type\": \"full_name | passport_number | birth_date | address | phone | email | face | qr_code\",\\n      \"content\": \"Мике Лорem, 123-124\",\\n      \"confidence\": \"high\"\\n    }\\n  ]\\n}\\n```\\n\\nВ этот JSON входит:\\n\\n1. Есть примеры для всех категорий.\\n2. Есть координаты для лица (face), но they are на текущем изображения.\\n3. Нема единицы в координатах, но это зависит от изображения\\'s размера.\\n4. Нема QR кодов в изображении.\\n5. Этот JSON демонстрирует единицу данных с координатами и типом данных.\\n\\nВнимание, эти данные сугубо будут проверяться и собираться с реальных документов, а не из lorem ipsum и других sample текстов.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce = generate_caption(image)\n",
    "responce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "303807f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"pii_detections\": [\n",
      "    {\n",
      "      \"bbox\": [0.239,0.537,0.494,0.829],\n",
      "      \"type\": \"full_name | passport_number | birth_date | address | phone | email | face | qr_code\",\n",
      "      \"content\": \"Мике Лорem, 123-124\",\n",
      "      \"confidence\": \"high\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "В этот JSON входит:\n",
      "\n",
      "1. Есть примеры для всех категорий.\n",
      "2. Есть координаты для лица (face), но they are на текущем изображения.\n",
      "3. Нема единицы в координатах, но это зависит от изображения's размера.\n",
      "4. Нема QR кодов в изображении.\n",
      "5. Этот JSON демонстрирует единицу данных с координатами и типом данных.\n",
      "\n",
      "Внимание, эти данные сугубо будут проверяться и собираться с реальных документов, а не из lorem ipsum и других sample текстов.\n"
     ]
    }
   ],
   "source": [
    "print(responce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
